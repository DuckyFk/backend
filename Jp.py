import torch
from transformers import T5ForConditionalGeneration, T5Tokenizer
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import base64
from PIL import Image, ImageDraw, ImageFont
import io
import os
import time
import re
from typing import List, Dict, Tuple, Optional

print("ğŸ”„ æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™... (åˆå›å®Ÿè¡Œæ™‚ã¯æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)")

model_name = "sonoisa/t5-base-japanese"
tokenizer = T5Tokenizer.from_pretrained(model_name)
model = T5ForConditionalGeneration.from_pretrained(model_name)
model.eval()
embedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')
kb = None
chatbot = None

print("âœ… ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸ!")

def initialize_bot():
    global kb, chatbot
    kb = EnhancedBusinessKnowledgeBase(business_data, embedding_model)
    chatbot = EnhancedBusinessChatbot(model, tokenizer, kb)

business_data = [
    {
        "question": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã¯ä½•ã‚’ã™ã‚‹ä¼šç¤¾ã§ã™ã‹ï¼Ÿ",
        "answer": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã¯ã€æ±äº¬ã‚’æ‹ ç‚¹ã¨ã™ã‚‹B2Bãƒ•ã‚£ãƒ³ãƒ†ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã§ã€æ©Ÿé–¢æŠ•è³‡å®¶ã‚„ã‚¢ã‚»ãƒƒãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ãƒ‡ãƒ¼ã‚¿é‹ç”¨ã‚’é©æ–°ã™ã‚‹åŒ…æ‹¬çš„ãªSaaSãƒ‡ãƒ¼ã‚¿ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚å½“ç¤¾ã®AIæ­è¼‰ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã¯ã€è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚’è‡ªå‹•åŒ–ã—ã€è‡ªå‹•ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚éæ§‹é€ åŒ–é‡‘èãƒ‡ãƒ¼ã‚¿ã‚’å®Ÿç”¨çš„ãªæ´å¯Ÿã«å¤‰æ›ã—ã€æŠ•è³‡ãƒãƒ¼ãƒ ã®æ‰‹ä½œæ¥­ã«ã‚ˆã‚‹Excelä½œæ¥­ã‚’æœ€å¤§80%å‰Šæ¸›ã™ã‚‹ã“ã¨ã‚’å°‚é–€ã¨ã—ã¦ã„ã¾ã™ã€‚å½“ç¤¾ã®ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã¯æ—¢å­˜ã®ã‚·ã‚¹ãƒ†ãƒ ã¨ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ±åˆã•ã‚Œã€å¤§è¦æ¨¡ãªæ©Ÿé–¢æŠ•è³‡å®¶ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’ç®¡ç†ã™ã‚‹ãŸã‚ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã‚’æä¾›ã—ã¾ã™ã€‚",
        "category": "company_overview",
        "image_path": "images/company_overview.png",
        "related_topics": ["ã‚µãƒ¼ãƒ“ã‚¹", "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼", "è‡ªå‹•åŒ–"],
        "keywords": ["ã™ã‚‹", "ä¼šç¤¾", "ãƒ“ã‚¸ãƒã‚¹", "ã«ã¤ã„ã¦", "æ¦‚è¦", "ã‚µãƒ¼ãƒ“ã‚¹", "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«", "ã‚¢ãƒ«ãƒ•ã‚¡", "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡", "ä½•ã‚’ã™ã‚‹", "ä½•ã‚’ã™ã‚‹ä¼šç¤¾", "ã¨ã¯"]
    },
    {
        "question": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã®å°†æ¥ã®ç›®æ¨™ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "answer": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã¯ã€ã‚°ãƒ­ãƒ¼ãƒãƒ«ä¼æ¥­ã®é¡§å®¢åŸºç›¤ã‚’æ‹¡å¤§ã—ã€ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã‚ˆã‚Šåºƒç¯„ãªå›½éš›çš„ãªé¡§å®¢ã«æä¾›ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚ä¸–ç•Œã‚’ãƒªãƒ¼ãƒ‰ã™ã‚‹çµ„ç¹”ã¨ã®ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã‚·ãƒƒãƒ—ã‚’é€šã˜ã¦ã€ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡‘èã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã‘ã‚‹å­˜åœ¨æ„Ÿã‚’å¼·åŒ–ã—ã€æ©Ÿé–¢æŠ•è³‡å®¶ã®é€²åŒ–ã™ã‚‹ãƒ‹ãƒ¼ã‚ºã«å¿œãˆã‚‹ãŸã‚ã®ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç¶šã‘ã¦ã„ãè¨ˆç”»ã§ã™ã€‚",
        "category": "future_goals",
        "image_path": "images/future_goals.png",
        "related_topics": ["ã‚°ãƒ­ãƒ¼ãƒãƒ«å±•é–‹", "é¡§å®¢", "æˆé•·", "å›½éš›"],
        "keywords": ["å°†æ¥", "ç›®æ¨™", "æ‹¡å¤§", "ã‚°ãƒ­ãƒ¼ãƒãƒ«", "è¨ˆç”»", "ãƒ“ã‚¸ãƒ§ãƒ³", "ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—", "ä»Šå¾Œ", "æœªæ¥", "ã“ã‚Œã‹ã‚‰"]
    },
    {
        "question": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã¯ã„ã¤è¨­ç«‹ã•ã‚Œã¾ã—ãŸã‹ï¼Ÿ",
        "answer": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã¯ã€é‡‘èã‚»ã‚¯ã‚¿ãƒ¼ã®ãƒ‡ã‚¸ã‚¿ãƒ«ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãŒè‘—ã—ã„æ™‚æœŸã®2019å¹´12æœˆã«æ±äº¬ã§è¨­ç«‹ã•ã‚Œã¾ã—ãŸã€‚è¨­ç«‹ä»¥æ¥ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ™ãƒ¼ã‚¹ã¨ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼æ©Ÿèƒ½ã®ä¸¡é¢ã§æ€¥é€Ÿãªæˆé•·ã‚’é‚ã’ã¦ã„ã¾ã™ã€‚å½“ç¤¾ã¯ã€æ©Ÿé–¢æŠ•è³‡é‹ç”¨ã«ãŠã„ã¦ã‚ˆã‚ŠåŠ¹ç‡çš„ã§é€æ˜æ€§ãŒé«˜ãã€è‡ªå‹•åŒ–ã•ã‚ŒãŸã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å‰µé€ ã™ã‚‹ã¨ã„ã†ãƒ“ã‚¸ãƒ§ãƒ³ã‹ã‚‰ç”Ÿã¾ã‚Œã¾ã—ãŸã€‚å‰µæ¥­è€…ãŸã¡ã¯ã€æŠ•è³‡é‹ç”¨ã¨ãƒ‡ãƒ¼ã‚¿ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã‘ã‚‹è±Šå¯ŒãªçµŒé¨“ã‚’æ´»ã‹ã—ã€æ—¥æœ¬å¸‚å ´ã«ãŠã‘ã‚‹é«˜åº¦ãªãƒ•ã‚£ãƒ³ãƒ†ãƒƒã‚¯ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã®éœ€è¦ã®é«˜ã¾ã‚Šã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚",
        "category": "company_history",
        "image_path": "images/company_timeline.png",
        "related_topics": ["è¨­ç«‹", "æˆé•·", "æ±äº¬"],
        "keywords": ["è¨­ç«‹", "ã„ã¤", "å‰µç«‹", "é–‹å§‹", "æ­´å²", "2019", "èµ·æº", "å‰µæ¥­", "å§‹ã¾ã£ãŸ", "ã‚¹ã‚¿ãƒ¼ãƒˆ"]
    },
    {
        "question": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã®ãƒãƒ¼ãƒ ã®è¦æ¨¡ã¯ã©ã®ãã‚‰ã„ã§ã™ã‹ï¼Ÿ",
        "answer": "2025å¹´ç¾åœ¨ã€ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã¯å–ç· å½¹ã€æŠ€è¡“é¡§å•ã€ã‚³ã‚¢ã‚¹ã‚¿ãƒƒãƒ•ã‚’å«ã‚ã€15-20åç¨‹åº¦ã®é«˜åº¦ãªã‚¹ã‚­ãƒ«ã‚’æŒã¤ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‚’é›‡ç”¨ã—ã¦ã„ã¾ã™ã€‚å½“ç¤¾ã®ãƒãƒ¼ãƒ ã¯ã€ãƒ•ã‚£ãƒ³ãƒ†ãƒƒã‚¯ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã€é‡‘èã‚µãƒ¼ãƒ“ã‚¹ã«ã‚ãŸã‚‹å°‚é–€çŸ¥è­˜ã‚’æŒã¤ã€å¤šæ§˜ã§å›½éš›çš„ãªè¦–é‡ã‚’æŒã¤å¾“æ¥­å“¡ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚ä¸–ç•Œæœ‰æ•°ã®é‡‘èæ©Ÿé–¢ã€ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ä¼æ¥­ã€ã‚³ãƒ³ã‚µãƒ«ãƒ†ã‚£ãƒ³ã‚°ä¼šç¤¾ã§ã®çµŒé¨“ã‚’æŒã¤ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼ã¨å…±ã«ã€åŠ¹ç‡çš„ãªçµ„ç¹”æ§‹é€ ã‚’ç¶­æŒã—ã¦ã„ã¾ã™ã€‚å½“ç¤¾ã®æ–‡åŒ–ã¯ã€ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã€ç¶™ç¶šçš„ãªå­¦ç¿’ã€æ©Ÿé–¢æŠ•è³‡å®¶ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¸ã®å“è¶Šã—ãŸä¾¡å€¤æä¾›ã‚’é‡è¦–ã—ã¦ã„ã¾ã™ã€‚",
        "category": "team_info",
        "image_path": "images/team_structure.png",
        "related_topics": ["ã‚¹ã‚¿ãƒƒãƒ•", "å°‚é–€çŸ¥è­˜", "ä¼æ¥­æ–‡åŒ–"],
        "keywords": ["ãƒãƒ¼ãƒ ", "ã‚¹ã‚¿ãƒƒãƒ•", "å¾“æ¥­å“¡", "äººå“¡", "è¦æ¨¡", "ãƒ¡ãƒ³ãƒãƒ¼", "äººæ•°", "ã©ã®ãã‚‰ã„", "ä½•äºº", "ç¤¾å“¡"]
    },
    {
        "question": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã®ãƒªãƒ¼ãƒ€ãƒ¼ã¯èª°ã§ã™ã‹ï¼Ÿ",
        "answer": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã¯ã€æŠ•è³‡ç®¡ç†ãƒ‡ãƒ¼ã‚¿ã‚·ã‚¹ãƒ†ãƒ ã¨é‡‘èãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã«ãŠã‘ã‚‹è±Šå¯ŒãªçµŒé¨“ã‚’æŒã¤ãƒ™ãƒ†ãƒ©ãƒ³ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã€CEOã®ã‚¸ã‚§ãƒ•ãƒªãƒ¼ãƒ»ãƒ„ã‚¤ãŒç‡ã„ã¦ã„ã¾ã™ã€‚ã‚¸ã‚§ãƒ•ãƒªãƒ¼ã¯ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã‚’è¨­ç«‹ã™ã‚‹å‰ã«ã€ã‚¹ãƒ†ãƒ¼ãƒˆãƒ»ã‚¹ãƒˆãƒªãƒ¼ãƒˆãƒ»ã‚³ãƒ¼ãƒãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ã‚¦ã‚§ãƒªãƒ³ãƒˆãƒ³ãƒ»ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆãªã©ã®åé–€çµ„ç¹”ã§åƒãã€æ©Ÿé–¢æŠ•è³‡å®¶ãŒãƒ‡ãƒ¼ã‚¿ç®¡ç†ã¨ãƒ¬ãƒãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã«ãŠã„ã¦ç›´é¢ã™ã‚‹èª²é¡Œã«ã¤ã„ã¦æ·±ã„æ´å¯Ÿã‚’å¾—ã¾ã—ãŸã€‚å½¼ã®ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—ã¯ã€æŠ€è¡“çš„å°‚é–€çŸ¥è­˜ã¨æˆ¦ç•¥çš„ãƒ“ã‚¸ãƒ§ãƒ³ã‚’çµ„ã¿åˆã‚ã›ã€æ—¥æœ¬åŠã³ãã‚Œä»¥ä¸Šã®åœ°åŸŸã§æ©Ÿé–¢æŠ•è³‡å®¶ã«ã‚ˆã‚‹é‡‘èãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ã¨æ´»ç”¨ã‚’å¤‰é©ã™ã‚‹ã¨ã„ã†å½“ç¤¾ã®ä½¿å‘½ã‚’æ¨é€²ã—ã¦ã„ã¾ã™ã€‚",
        "category": "leadership",
        "image_path": "images/leadership_team.png",
        "related_topics": ["CEO", "çµŒé¨“", "èƒŒæ™¯"],
        "keywords": ["CEO", "ãƒªãƒ¼ãƒ€ãƒ¼", "å‰µæ¥­è€…", "çµŒå–¶é™£", "ãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆ", "ã‚¸ã‚§ãƒ•ãƒªãƒ¼", "ãƒ„ã‚¤", "èª°", "ç‡ã„ã¦ã„ã‚‹", "ãƒˆãƒƒãƒ—", "ä»£è¡¨"]
    },
    {
        "question": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«ã¯èª°ãŒã„ã¾ã™ã‹ï¼Ÿ",
        "answer": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã¯ã€æ—¥æœ¬ã®ä¸»è¦ãªã‚¢ã‚»ãƒƒãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚„å¹´é‡‘åŸºé‡‘ã‚’å«ã‚€ã€åé–€æ©Ÿé–¢æŠ•è³‡å®¶ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã«ã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚æ³¨ç›®ã™ã¹ãã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«ã¯ã€æ—¥æœ¬æœ€å¤§ç´šã®ä¼æ¥­å¹´é‡‘åŸºé‡‘ã®ä¸€ã¤ã§ã‚ã‚‹ãƒ™ãƒãƒƒã‚»ã‚°ãƒ«ãƒ¼ãƒ—å¹´é‡‘åŸºé‡‘ã€å¤§æ‰‹è³‡ç”£é‹ç”¨ä¼šç¤¾ã®ä¸‰äº•ä½å‹DSã‚¢ã‚»ãƒƒãƒˆãƒãƒã‚¸ãƒ¡ãƒ³ãƒˆã€ã‚³ãƒ³ã‚µãƒ«ãƒ†ã‚£ãƒ³ã‚°ã‚µãƒ¼ãƒ“ã‚¹ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒªãƒ¼ãƒ€ãƒ¼ã§ã‚ã‚‹ãƒãƒ¼ã‚µãƒ¼ã‚¸ãƒ£ãƒ‘ãƒ³ãªã©ãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã‚‰ã®é–¢ä¿‚ã¯ã€å¤§è¦æ¨¡ãªæ©Ÿé–¢æŠ•è³‡å®¶ã®å³æ ¼ãªè¦ä»¶ã‚’æº€ãŸã™ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºã‚°ãƒ¬ãƒ¼ãƒ‰ã®ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã™ã‚‹å½“ç¤¾ã®èƒ½åŠ›ã‚’ç¤ºã—ã¦ãŠã‚Šã€è¤‡é›‘ãªãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªç®¡ç†ã€è¦åˆ¶å ±å‘Šã€ãƒ‡ãƒ¼ã‚¿åˆ†æã®ãƒ‹ãƒ¼ã‚ºã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚",
        "category": "clients",
        "image_path": "images/client_logos.png",
        "related_topics": ["æ©Ÿé–¢æŠ•è³‡å®¶", "å¹´é‡‘åŸºé‡‘", "ã‚¢ã‚»ãƒƒãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"],
        "keywords": ["ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ", "é¡§å®¢", "ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼", "ãƒ™ãƒãƒƒã‚»", "ä¸‰äº•ä½å‹", "ãƒãƒ¼ã‚µãƒ¼", "èª°", "å–å¼•å…ˆ", "ãŠå®¢æ§˜", "ä¼æ¥­"]
    },
    {
        "question": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã¯ã©ã®ã‚ˆã†ãªãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ",
        "answer": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã®ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚¹ã‚¿ãƒƒã‚¯ã¯ã€é«˜æ€§èƒ½ãªé‡‘èãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸæœ€æ–°ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«åŸºã¥ã„ã¦æ§‹ç¯‰ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã¯NodeJSã‚’ä½¿ç”¨ã—ã¦ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰é–‹ç™ºã‚’è¡Œã„ã€é«˜é€Ÿã§åŠ¹ç‡çš„ãªãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã¯Reactã§æ§‹ç¯‰ã•ã‚Œã€ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ã§ç›´æ„Ÿçš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æä¾›ã—ã¾ã™ã€‚ç‰¹å®šã®Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¯Laravelãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã—ãŸPHPã‚’ä½¿ç”¨ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å±¤ã¯ä¿¡é ¼æ€§ã®é«˜ã„ãƒ‡ãƒ¼ã‚¿ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®ãŸã‚ã«MySQLã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚APIã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã¯ã€æŸ”è»Ÿãªãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹ã®ãŸã‚ã«GraphQLã¨RESTful APIã®ä¸¡æ–¹ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã¯AWSã‚’é€šã˜ã¦ç®¡ç†ã•ã‚Œã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’æä¾›ã—ã€Dockerã‚³ãƒ³ãƒ†ãƒŠãŒä¸€è²«ã—ãŸãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆç’°å¢ƒã‚’ä¿è¨¼ã—ã¾ã™ã€‚CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¯ã€è‡ªå‹•ãƒ†ã‚¹ãƒˆã¨ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆã®ãŸã‚ã«CircleCIã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚",
        "category": "technology",
        "image_path": "images/tech_stack.png",
        "related_topics": ["nodejs", "react", "aws", "api"],
        "keywords": ["ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼", "æŠ€è¡“", "ã‚¹ã‚¿ãƒƒã‚¯", "ãƒ„ãƒ¼ãƒ«", "ä½¿ç”¨", "ä½¿ã£ã¦ã„ã‚‹", "ä½¿ç”¨ã—ã¦ã„ã‚‹", "nodejs", "react", "aws", "docker", "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹", "ã©ã®ã‚ˆã†ãª", "ã©ã‚“ãª", "æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯", "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚¹ã‚¿ãƒƒã‚¯", "ã©ã®ã‚ˆã†ãªãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼", "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚’ä½¿ç”¨"]
    },
    {
        "question": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã®ä¸»ãªã‚µãƒ¼ãƒ“ã‚¹ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "answer": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã¯ã€æ©Ÿé–¢æŠ•è³‡å®¶å‘ã‘ã«ç‰¹åˆ¥ã«è¨­è¨ˆã•ã‚ŒãŸåŒ…æ‹¬çš„ãªé‡‘èãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹ã®ã‚¹ã‚¤ãƒ¼ãƒˆã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚å½“ç¤¾ã®ã‚³ã‚¢ã‚µãƒ¼ãƒ“ã‚¹ã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã¾ã™ï¼š1) éæ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿å‡¦ç† - è¤‡é›‘ãªé‡‘èæ–‡æ›¸ã€ãƒ¬ãƒãƒ¼ãƒˆã€ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’æ§‹é€ åŒ–ã•ã‚ŒãŸå®Ÿç”¨çš„ãªæƒ…å ±ã«å¤‰æ›ã€2) ã‚³ãƒ³ãƒ†ãƒ³ãƒ„è‡ªå‹•åŒ– - æ‰‹ä½œæ¥­ã®æ™‚é–“ã‚’ç¯€ç´„ã™ã‚‹è‡ªå‹•ãƒ¬ãƒãƒ¼ãƒˆã€ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€åˆ†ææ–‡æ›¸ã®ç”Ÿæˆã€3) ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ˆç®— - æ­£ç¢ºã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ã‚¢ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æã®æä¾›ã€4) ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚° - æŠ•è³‡ãƒã‚¸ã‚·ãƒ§ãƒ³ã€ãƒªã‚¹ã‚¯ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã€ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹è¦ä»¶ã®ç¶™ç¶šçš„ãªè¿½è·¡ã€‚ã™ã¹ã¦ã®ã‚µãƒ¼ãƒ“ã‚¹ã¯ã€å¤§è¦æ¨¡ãªæ©Ÿé–¢æŠ•è³‡ã‚’ç®¡ç†ã™ã‚‹é‡‘èå°‚é–€å®¶å‘ã‘ã«èª¿æ•´ã•ã‚Œã€æ—¢å­˜ã®æŠ•è³‡ç®¡ç†ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¨ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ±åˆã•ã‚Œã¾ã™ã€‚",
        "category": "services",
        "image_path": "images/services_overview.png",
        "related_topics": ["ãƒ‡ãƒ¼ã‚¿å‡¦ç†", "è‡ªå‹•åŒ–", "ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªç®¡ç†"],
        "keywords": ["ã‚µãƒ¼ãƒ“ã‚¹", "æä¾›", "è£½å“", "ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³", "æ©Ÿèƒ½", "èƒ½åŠ›", "ä¸»ãª", "ä¸»è¦", "ã‚³ã‚¢", "ãƒ¡ã‚¤ãƒ³"]
    },
    {
        "question": "ãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’å‰Šé™¤ã™ã‚‹ã«ã¯ã©ã†ã™ã‚Œã°ã‚ˆã„ã§ã™ã‹ï¼Ÿ",
        "answer": "ã¾ãšã€ãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’å‰Šé™¤ã™ã‚‹ã«ã¯ç®¡ç†è€…ã‚¢ã‚¯ã‚»ã‚¹ãŒå¿…è¦ã§ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ¼ã‹ã‚‰ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆâ†’ãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’å‰Šé™¤ã—ãŸã„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ã‚¯ãƒªãƒƒã‚¯â†’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒãƒ³ãƒ‡ãƒ¼ãƒˆæ¦‚è¦ãƒšãƒ¼ã‚¸ã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã•ã‚Œã€ãã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é–¢é€£ä»˜ã‘ã‚‰ã‚Œã¦ã„ã‚‹ã™ã¹ã¦ã®ãƒãƒ³ãƒ‡ãƒ¼ãƒˆã®ãƒªã‚¹ãƒˆãŒè¡¨ç¤ºã•ã‚Œã¾ã™â†’å‰Šé™¤ã—ãŸã„ãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’ã‚¯ãƒªãƒƒã‚¯â†’ãƒãƒ³ãƒ‡ãƒ¼ãƒˆè©³ç´°ãƒšãƒ¼ã‚¸ã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã•ã‚Œã¾ã™â†’å³ä¸Šéš…ã®ã€Œ...ã€ã‚’ã‚¯ãƒªãƒƒã‚¯â†’é–‹ã„ãŸãƒªã‚¹ãƒˆã‹ã‚‰ã€Œãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’å‰Šé™¤ã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚",
        "category": "mandate_management",
        "image_path": "images/delete_mandate.png",
        "related_topics": ["ãƒãƒ³ãƒ‡ãƒ¼ãƒˆ", "å‰Šé™¤", "ç®¡ç†è€…", "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç®¡ç†"],
        "keywords": ["å‰Šé™¤", "ãƒãƒ³ãƒ‡ãƒ¼ãƒˆ", "é™¤å»", "æ–¹æ³•", "ç®¡ç†è€…", "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"]
    },
    {
        "question": "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’å‰Šé™¤ã™ã‚‹æ‰‹é †ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "answer": "ãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’å‰Šé™¤ã™ã‚‹ã«ã¯ã€ç®¡ç†è€…ã‚¢ã‚¯ã‚»ã‚¹ãŒå¿…è¦ã§ã™ã€‚ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ¼ã‹ã‚‰ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«ç§»å‹•ã—ã€ç‰¹å®šã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’é¸æŠã—ã€ã™ã¹ã¦ã®ãƒãƒ³ãƒ‡ãƒ¼ãƒˆãŒè¡¨ç¤ºã•ã‚Œã‚‹ãƒãƒ³ãƒ‡ãƒ¼ãƒˆæ¦‚è¦ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºã—ã€å¯¾è±¡ã®ãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒãƒ³ãƒ‡ãƒ¼ãƒˆè©³ç´°ã‚’é–‹ãã€å³ä¸Šéš…ã®ã€Œ...ã€ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‹ã‚‰ã€Œãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’å‰Šé™¤ã€ã‚’é¸æŠã—ã¾ã™ã€‚",
        "category": "mandate_management",
        "image_path": "images/delete_mandate.png",
        "related_topics": ["ãƒãƒ³ãƒ‡ãƒ¼ãƒˆ", "å‰Šé™¤", "ç®¡ç†è€…", "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç®¡ç†"],
        "keywords": ["é™¤å»", "ãƒãƒ³ãƒ‡ãƒ¼ãƒˆ", "å‰Šé™¤", "æ‰‹é †", "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ", "ç®¡ç†è€…"]
    },
    {
        "question": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã§ãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’å‰Šé™¤ã™ã‚‹ã«ã¯ã©ã†ã™ã‚Œã°ã‚ˆã„ã§ã™ã‹ï¼Ÿ",
        "answer": "ãƒãƒ³ãƒ‡ãƒ¼ãƒˆã®å‰Šé™¤ã«ã¯ç®¡ç†è€…ã‚¢ã‚¯ã‚»ã‚¹ãŒå¿…è¦ã§ã™ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ¼ã‹ã‚‰ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã€ãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’å‰Šé™¤ã—ãŸã„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’é¸æŠã—ã¾ã™ã€‚ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒãƒ³ãƒ‡ãƒ¼ãƒˆæ¦‚è¦ãƒšãƒ¼ã‚¸ã§ã€é–¢é€£ã™ã‚‹ã™ã¹ã¦ã®ãƒãƒ³ãƒ‡ãƒ¼ãƒˆãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚å‰Šé™¤ã—ãŸã„ãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒãƒ³ãƒ‡ãƒ¼ãƒˆè©³ç´°ãƒšãƒ¼ã‚¸ã‚’é–‹ãã¾ã™ã€‚æ¬¡ã«ã€å³ä¸Šéš…ã®ã€Œ...ã€ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‹ã‚‰ã€Œãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’å‰Šé™¤ã€ã‚’é¸æŠã—ã¾ã™ã€‚",
        "category": "mandate_management",
        "image_path": "images/delete_mandate.png",
        "related_topics": ["ãƒãƒ³ãƒ‡ãƒ¼ãƒˆ", "å‰Šé™¤", "ç®¡ç†è€…", "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç®¡ç†"],
        "keywords": ["å‰Šé™¤", "ãƒãƒ³ãƒ‡ãƒ¼ãƒˆ", "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡", "æ–¹æ³•", "ç®¡ç†è€…"]
    },
    {
        "question": "ãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’å‰Šé™¤ã™ã‚‹ã«ã¯ã©ã®ã‚ˆã†ãªæ¨©é™ãŒå¿…è¦ã§ã™ã‹ï¼Ÿ",
        "answer": "ãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’å‰Šé™¤ã™ã‚‹ã«ã¯ç®¡ç†è€…ã‚¢ã‚¯ã‚»ã‚¹ãŒå¿…è¦ã§ã™ã€‚ç®¡ç†è€…æ¨©é™ã‚’æŒã£ã¦ã„ã‚‹å ´åˆã¯ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆâ†’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’é¸æŠâ†’ãƒãƒ³ãƒ‡ãƒ¼ãƒˆæ¦‚è¦ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤ºâ†’ç‰¹å®šã®ãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’ã‚¯ãƒªãƒƒã‚¯â†’ãƒãƒ³ãƒ‡ãƒ¼ãƒˆè©³ç´°ãƒšãƒ¼ã‚¸ã‚’é–‹ãâ†’å³ä¸Šéš…ã®ã€Œ...ã€ã‚’ã‚¯ãƒªãƒƒã‚¯â†’ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ã€Œãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’å‰Šé™¤ã€ã‚’é¸æŠã—ã¾ã™ã€‚",
        "category": "mandate_management",
        "image_path": "images/delete_mandate.png",
        "related_topics": ["ãƒãƒ³ãƒ‡ãƒ¼ãƒˆ", "å‰Šé™¤", "ç®¡ç†è€…", "æ¨©é™"],
        "keywords": ["æ¨©é™", "ç®¡ç†è€…", "å‰Šé™¤", "ãƒãƒ³ãƒ‡ãƒ¼ãƒˆ", "ã‚¢ã‚¯ã‚»ã‚¹"]
    },
    {
        "question": "ç®¡ç†è€…ã‚¢ã‚¯ã‚»ã‚¹ãªã—ã§ãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’å‰Šé™¤ã§ãã¾ã™ã‹ï¼Ÿ",
        "answer": "ã„ã„ãˆã€ç®¡ç†è€…ã‚¢ã‚¯ã‚»ã‚¹ãªã—ã§ã¯ãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’å‰Šé™¤ã§ãã¾ã›ã‚“ã€‚ãƒãƒ³ãƒ‡ãƒ¼ãƒˆã®å‰Šé™¤ã«ã¯ç®¡ç†è€…ã‚¢ã‚¯ã‚»ã‚¹ãŒå¿…è¦ã§ã™ã€‚ç®¡ç†è€…ã‚¢ã‚¯ã‚»ã‚¹ã‚’ãŠæŒã¡ã®å ´åˆã¯ã€æ¬¡ã®æ‰‹é †ã«å¾“ã£ã¦ãã ã•ã„ï¼šãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ¼ã‹ã‚‰ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ã‚¯ãƒªãƒƒã‚¯â†’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’é¸æŠâ†’ãƒãƒ³ãƒ‡ãƒ¼ãƒˆæ¦‚è¦ãƒšãƒ¼ã‚¸ã«ç§»å‹•â†’å‰Šé™¤ã™ã‚‹ãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’ã‚¯ãƒªãƒƒã‚¯â†’ãƒãƒ³ãƒ‡ãƒ¼ãƒˆè©³ç´°ã‚’é–‹ãâ†’å³ä¸Šã®ã€Œ...ã€ã‚’ã‚¯ãƒªãƒƒã‚¯â†’ã€Œãƒãƒ³ãƒ‡ãƒ¼ãƒˆã‚’å‰Šé™¤ã€ã‚’é¸æŠã—ã¾ã™ã€‚",
        "category": "mandate_management",
        "image_path": "images/delete_mandate.png",
        "related_topics": ["ãƒãƒ³ãƒ‡ãƒ¼ãƒˆ", "å‰Šé™¤", "ç®¡ç†è€…", "æ¨©é™"],
        "keywords": ["ç®¡ç†è€…", "ã‚¢ã‚¯ã‚»ã‚¹", "é™¤å»", "ãƒãƒ³ãƒ‡ãƒ¼ãƒˆ", "æ¨©é™", "ãªã—"]
    }
]

def create_sample_images():
    if not os.path.exists('images'):
        os.makedirs('images')
        print("ğŸ“ ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã—ãŸ")
    
    image_configs = [
        {'name': 'company_overview.png', 'text': 'Visual Alpha\nFintech Solutions', 'color': '#2563eb'},
        {'name': 'company_timeline.png', 'text': 'Founded 2019\nTokyo, Japan', 'color': '#059669'},
        {'name': 'team_structure.png', 'text': '15-20 Staff\nGlobal Team', 'color': '#dc2626'},
        {'name': 'leadership_team.png', 'text': 'Jeffrey Tsui\nCEO', 'color': '#7c3aed'},
        {'name': 'client_logos.png', 'text': 'Enterprise Clients\nInstitutional', 'color': '#ea580c'},
        {'name': 'tech_stack.png', 'text': 'NodeJS â€¢ React\nAWS â€¢ Docker', 'color': '#0891b2'},
        {'name': 'services_overview.png', 'text': 'Data Processing\nAutomation', 'color': '#be185d'},
        {'name': 'future_goals.png', 'text': 'Global Expansion\nGrowth', 'color': '#16a34a'}
    ]
    
    created_count = 0
    for config in image_configs:
        image_path = f"images/{config['name']}"
        if not os.path.exists(image_path):
            img = Image.new('RGB', (400, 200), color=config['color'])
            draw = ImageDraw.Draw(img)
            
            try:
                font = ImageFont.truetype("arial.ttf", 20)
            except:
                try:
                    font = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", 20) 
                except:
                    font = ImageFont.load_default()
            
            bbox = draw.textbbox((0, 0), config['text'], font=font)
            text_width = bbox[2] - bbox[0]
            text_height = bbox[3] - bbox[1]
            
            x = (400 - text_width) // 2
            y = (200 - text_height) // 2
            
            draw.text((x, y), config['text'], fill='white', font=font)
            img.save(image_path)
            created_count += 1
            print(f"âœ… ä½œæˆã—ã¾ã—ãŸ: {image_path}")
    
    if created_count == 0:
        print("â„¹ï¸  ã™ã¹ã¦ã®ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
    else:
        print(f"ğŸ¨ {created_count}å€‹ã®ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã‚’ä½œæˆã—ã¾ã—ãŸ")

class EnhancedBusinessKnowledgeBase:
    def __init__(self, data, embedding_model):
        self.data = data
        self.embedding_model = embedding_model
        self.index = None
        self.category_index = {}
        self.keyword_index = {}
        self.build_index()

    def build_index(self):
        # Build semantic embeddings
        texts = [f"{item['question']} {item['answer']} {' '.join(item.get('related_topics', []))}" 
                for item in self.data]
        embeddings = self.embedding_model.encode(texts)
        dimension = embeddings.shape[1]
        self.index = faiss.IndexFlatIP(dimension)
        faiss.normalize_L2(embeddings)
        self.index.add(embeddings.astype('float32'))
        
        # Build category index
        for i, item in enumerate(self.data):
            category = item.get('category', 'general')
            if category not in self.category_index:
                self.category_index[category] = []
            self.category_index[category].append(i)
            
            # Build keyword index for fallback matching
            keywords = item.get('keywords', [])
            for keyword in keywords:
                keyword_lower = keyword.lower()
                if keyword_lower not in self.keyword_index:
                    self.keyword_index[keyword_lower] = []
                self.keyword_index[keyword_lower].append(i)

    def keyword_match(self, query):
        """Fallback keyword matching for better recall"""
        query_lower = query.lower().strip()
        
        # Check for exact phrase matches first
        matches = {}
        for keyword in self.keyword_index:
            if keyword in query_lower:
                for idx in self.keyword_index[keyword]:
                    # Give higher weight to phrase matches
                    weight = len(keyword.split())
                    matches[idx] = matches.get(idx, 0) + weight
        
        # Also check individual words (for Japanese, check characters)
        query_words = re.findall(r'\w+', query_lower)
        for word in query_words:
            if word in self.keyword_index:
                for idx in self.keyword_index[word]:
                    matches[idx] = matches.get(idx, 0) + 0.5
        
        # Return indices sorted by match count
        if matches:
            sorted_matches = sorted(matches.items(), key=lambda x: x[1], reverse=True)
            return [idx for idx, count in sorted_matches if count >= 1]
        return []

    def search(self, query, top_k=2, min_score=0.30):
        """Hybrid search: semantic + keyword matching"""
        query_lower = query.lower().strip()
        
        # First try keyword matching for better precision on specific queries
        keyword_matches = self.keyword_match(query)
        
        # Debug: Print keyword matches
        if keyword_matches:
            print(f"ğŸ” Keyword matches found: {[self.data[idx]['question'][:50] for idx in keyword_matches[:3]]}")
        
        # Semantic search
        query_embedding = self.embedding_model.encode([query])
        faiss.normalize_L2(query_embedding)
        scores, indices = self.index.search(query_embedding.astype('float32'), top_k)

        # Debug: Print semantic matches
        print(f"ğŸ” Semantic matches: {[(self.data[idx]['question'][:50], float(scores[0][i])) for i, idx in enumerate(indices[0])]}")

        results = []
        
        # If we have a strong keyword match, prioritize it
        if keyword_matches:
            idx = keyword_matches[0]
            # Check if this is also in semantic results
            if idx in indices[0]:
                sem_idx = list(indices[0]).index(idx)
                score = float(scores[0][sem_idx])
            else:
                score = 0.6  # Give good score to keyword matches
            
            print(f"âœ… Using keyword match: {self.data[idx]['question'][:60]}")
            
            results.append({
                'text': self.data[idx]['answer'],
                'score': score,
                'question': self.data[idx]['question'],
                'category': self.data[idx].get('category', 'general'),
                'image_path': self.data[idx].get('image_path'),
                'related_topics': self.data[idx].get('related_topics', []),
                'match_type': 'keyword'
            })
            return results
        
        # Otherwise use semantic results
        for idx, score in zip(indices[0], scores[0]):
            if score > min_score:
                results.append({
                    'text': self.data[idx]['answer'],
                    'score': float(score),
                    'question': self.data[idx]['question'],
                    'category': self.data[idx].get('category', 'general'),
                    'image_path': self.data[idx].get('image_path'),
                    'related_topics': self.data[idx].get('related_topics', []),
                    'match_type': 'semantic'
                })
        
        if results:
            print(f"âœ… Using semantic match: {results[0]['question'][:60]}")
        
        return results

    def get_related_content(self, category, exclude_idx=None):
        if category in self.category_index:
            related = []
            for idx in self.category_index[category]:
                if exclude_idx is None or idx != exclude_idx:
                    related.append(self.data[idx])
            return related[:2]
        return []

    def get_response(self, query: str) -> Dict:
        """Legacy method for backward compatibility"""
        try:
            results = self.search(query, top_k=1, min_score=0.30)
            
            if not results:
                return {
                    'answer': 'ã™ã¿ã¾ã›ã‚“ã€ãã®è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚',
                    'confidence': 'ä½',
                    'distance': 999,
                    'related_topics': []
                }
            
            best_match = results[0]
            score = best_match['score']
            
            # Convert score to distance-like metric for backward compatibility
            distance = 1.0 - score if score > 0 else 999
            confidence = "é«˜" if score > 0.5 else "ä¸­" if score > 0.35 else "ä½"
            
            return {
                'answer': best_match['text'],
                'confidence': confidence,
                'distance': distance,
                'related_topics': best_match.get('related_topics', []),
                'image_path': best_match.get('image_path'),
                'category': best_match.get('category', 'general')
            }
        except Exception as e:
            print(f"Error in get_response: {str(e)}")
            return {
                'answer': 'ã™ã¿ã¾ã›ã‚“ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚',
                'confidence': 'ä½',
                'distance': 999,
                'related_topics': []
            }

class EnhancedBusinessChatbot:
    def __init__(self, model, tokenizer, knowledge_base):
        self.model = model
        self.tokenizer = tokenizer
        self.kb = knowledge_base
        self.knowledge_base = knowledge_base  # For backward compatibility
        self.conversation_history = []
        
        # Configuration
        self.confidence_threshold = 0.30
        self.use_direct_answers = True
        self.max_response_length = 500

    def clean_response(self, response):
        """Clean and validate the response"""
        sentences = response.split('ã€‚')
        seen = set()
        clean_sentences = []
        
        for sentence in sentences:
            sentence = sentence.strip()
            if sentence and sentence not in seen and len(sentence) > 10:
                seen.add(sentence)
                clean_sentences.append(sentence)
        
        cleaned = 'ã€‚'.join(clean_sentences)
        if cleaned and not cleaned.endswith('ã€‚'):
            cleaned += 'ã€‚'
        
        if len(cleaned) > self.max_response_length:
            cleaned = cleaned[:self.max_response_length].rsplit('ã€‚', 1)[0] + 'ã€‚'
        
        return cleaned

    def validate_response(self, response, original_answer):
        """Check if response looks valid"""
        # Remove Japanese punctuation for word count
        words = re.findall(r'[\w]+', response)
        if len(words) > 10:
            unique_words = len(set(words))
            if unique_words / len(words) < 0.3:
                return False
        
        if re.search(r'(.{20,}?)\1{2,}', response):
            return False
        
        if re.search(r'([ã€‚ã€ï¼›ï¼ï¼Ÿ])\1{3,}', response):
            return False
        
        return True

    def generate_detailed_response(self, user_query, max_length=400) -> Tuple[str, Optional[str], List[str]]:
        user_query = user_query.strip()
        if not user_query:
            return self._handle_out_of_context("Empty query")
        
        relevant_docs = self.kb.search(user_query, top_k=2, min_score=self.confidence_threshold)
        
        if not relevant_docs:
            return self._handle_out_of_context(user_query)
        
        best_match = relevant_docs[0]
        response = best_match['text']
        
        if not self.validate_response(response, best_match['text']):
            response = best_match['text']
        
        response = self.clean_response(response)
        
        if len(response) < 50 or not self.validate_response(response, best_match['text']):
            response = best_match['text']
        
        image_path = best_match.get('image_path')
        related_topics = best_match.get('related_topics', [])
        
        self.conversation_history.append({
            'query': user_query,
            'response': response,
            'image_path': image_path,
            'topics': related_topics,
            'score': best_match['score'],
            'match_type': best_match.get('match_type', 'semantic')
        })
        
        return response, image_path, related_topics

    def _handle_out_of_context(self, user_query) -> Tuple[str, None, List[str]]:
        """Handle questions outside knowledge base"""
        response = """ãã®æƒ…å ±ã¯æŒã£ã¦ã„ã¾ã›ã‚“ã€‚ä»Šå¾Œã®æ›´æ–°ã‚’ãŠå¾…ã¡ã„ãŸã ãã‹ã€ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ¼ã‹ã‚‰è³ªå•ã¨å›ç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚

ç¾åœ¨ã®çŸ¥è­˜ã«åŸºã¥ã„ã¦ã€ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã«é–¢ã™ã‚‹ä»¥ä¸‹ã®è³ªå•ã«ã®ã¿å›ç­”ã§ãã¾ã™ï¼š
â€¢ ä¼šç¤¾æ¦‚è¦ã¨ã‚µãƒ¼ãƒ“ã‚¹
â€¢ ãƒªãƒ¼ãƒ€ãƒ¼ã‚·ãƒƒãƒ—ã¨ãƒãƒ¼ãƒ æƒ…å ±
â€¢ ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚¹ã‚¿ãƒƒã‚¯ã¨ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³
â€¢ ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæƒ…å ±
â€¢ ä¼šç¤¾ã®æ­´å²ã¨è¨­ç«‹
â€¢ å°†æ¥ã®ç›®æ¨™ã¨æ‹¡å¤§è¨ˆç”»

ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã«é–¢é€£ã™ã‚‹è³ªå•ã‚’ã—ã¦ãã ã•ã„ã€‚"""
        
        return response, None, []

    def get_response(self, query: str) -> Dict:
        """Main response method with backward compatibility"""
        try:
            print(f"Processing query in chatbot: {query}")
            
            response, image_path, related_topics = self.generate_detailed_response(query)
            
            image_base64 = None
            if image_path:
                try:
                    # Try relative path first
                    if os.path.exists(image_path):
                        img_path_to_use = image_path
                    else:
                        # Try parent directory path
                        img_path_to_use = os.path.join(os.path.dirname(os.path.dirname(__file__)), image_path)
                    
                    if os.path.exists(img_path_to_use):
                        with Image.open(img_path_to_use) as img:
                            if img.mode == 'RGBA':
                                img = img.convert('RGB')
                            
                            img_byte_arr = io.BytesIO()
                            img.save(img_byte_arr, format='JPEG')
                            img_byte_arr = img_byte_arr.getvalue()
                            
                            image_base64 = base64.b64encode(img_byte_arr).decode('utf-8')
                    else:
                        print(f"ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
                except Exception as e:
                    print(f"ç”»åƒã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")

            # Determine confidence based on image availability and response content
            if image_path and image_base64:
                confidence = 'é«˜'
            elif "ãã®æƒ…å ±ã¯æŒã£ã¦ã„ã¾ã›ã‚“" in response:
                confidence = 'ä½'
            else:
                confidence = 'ä¸­'

            return {
                'response': response,
                'image_base64': image_base64,
                'confidence': confidence,
                'related_topics': related_topics
            }
        except Exception as e:
            print(f"Error in chatbot response: {str(e)}")
            return {
                'response': 'ã™ã¿ã¾ã›ã‚“ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚',
                'image_base64': None,
                'confidence': 'ä½',
                'related_topics': []
            }

def encode_image_to_base64(image_path):
    try:
        if os.path.exists(image_path):
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
    except Exception as e:
        print(f"ç”»åƒã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
    return None

def create_placeholder_image(text="Visual Alpha", size=(400, 200)):
    img = Image.new('RGB', (400, 200), color='#1f2937')
    draw = ImageDraw.Draw(img)
    
    try:
        font = ImageFont.truetype("arial.ttf", 16)
    except:
        font = ImageFont.load_default()
    
    bbox = draw.textbbox((0, 0), text, font=font)
    text_width = bbox[2] - bbox[0]
    text_height = bbox[3] - bbox[1]
    x = (size[0] - text_width) // 2
    y = (size[1] - text_height) // 2
    
    draw.text((x, y), text, fill='white', font=font)
    return img

def enhanced_chat_response(message: str) -> dict:
    """Main entry point for chat responses"""
    if chatbot is None:
        return {
            "response": "ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
            "image_base64": None,
            "confidence": "ä½",
            "related_topics": []
        }
    
    try:
        result = chatbot.get_response(message)
        return {
            "response": result['response'],
            "image_base64": result.get('image_base64'),
            "confidence": result.get('confidence', 'ä½'),
            "related_topics": result.get('related_topics', [])
        }
    except Exception as e:
        print(f"Error in enhanced_chat_response: {str(e)}")
        return {
            "response": "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
            "image_base64": None,
            "confidence": "ä½",
            "related_topics": []
        }

def interactive_mode():
    print("\nğŸ¤– ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆçµ‚äº†ã™ã‚‹ã«ã¯'quit'ã¨å…¥åŠ›ï¼‰")
    print("ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã«ã¤ã„ã¦ä½•ã§ã‚‚è³ªå•ã—ã¦ãã ã•ã„ï¼")
    print("=" * 50)
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ ã‚ãªãŸ: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'q', 'çµ‚äº†']:
                print("ğŸ‘‹ ã•ã‚ˆã†ãªã‚‰ï¼")
                break
                
            if not user_input:
                print("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼")
                continue
                
            print("ğŸ¤– å‡¦ç†ä¸­... â³")
            
            result = enhanced_chat_response(user_input)
            
            print(f"\nğŸ¤– ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ:")
            print("-" * 40)
            print(result['response'])
            
            if result['image_base64']:
                timestamp = int(time.time())
                image_filename = f"chat_image_{timestamp}.png"
                image_data = base64.b64decode(result['image_base64'])
                with open(image_filename, 'wb') as f:
                    f.write(image_data)
                print(f"\nğŸ–¼ï¸  é–¢é€£ç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ: {image_filename}")
            
            if result['related_topics']:
                print(f"\nğŸ·ï¸  é–¢é€£ãƒˆãƒ”ãƒƒã‚¯: {', '.join(result['related_topics'])}")
            
            print(f"ğŸ“Š ä¿¡é ¼åº¦: {result['confidence']}")
                
        except KeyboardInterrupt:
            print("\nğŸ‘‹ ã•ã‚ˆã†ãªã‚‰ï¼")
            break
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")

def run_tests():
    test_questions = [
        "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã¯ä½•ã‚’ã™ã‚‹ä¼šç¤¾ã§ã™ã‹ï¼Ÿ",
        "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã¨ã¯",
        "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã‚¹ã‚¿ãƒƒã‚¯ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„", 
        "ãƒªãƒ¼ãƒ€ãƒ¼ã¯èª°ã§ã™ã‹ï¼Ÿ",
        "ä¸»ãªã‚µãƒ¼ãƒ“ã‚¹ã¯ä½•ã§ã™ã‹ï¼Ÿ",
        "ãƒãƒ¼ãƒ ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„",
        "ã„ã¤è¨­ç«‹ã•ã‚Œã¾ã—ãŸã‹ï¼Ÿ",
        "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯èª°ã§ã™ã‹ï¼Ÿ",
        "ä»Šæ—¥ã®å¤©æ°—ã¯ï¼Ÿ",
        "ç·ç†å¤§è‡£ã¯èª°ã§ã™ã‹ï¼Ÿ",
        "ãƒ”ã‚¶ã®ä½œã‚Šæ–¹ã¯ï¼Ÿ",
    ]
    
    print("\nğŸ§ª æ‹¡å¼µãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’ãƒ†ã‚¹ãƒˆä¸­:")
    print("=" * 50)
    
    total_tests = len(test_questions)
    passed_tests = 0
    
    for i, question in enumerate(test_questions, 1):
        print(f"\n[ãƒ†ã‚¹ãƒˆ {i}/{total_tests}] è³ªå•: {question}")
        
        try:
            start_time = time.time()
            result = enhanced_chat_response(question)
            end_time = time.time()
            
            response_time = end_time - start_time
            
            print(f"å›ç­” ({response_time:.1f}ç§’):")
            
            response_preview = result['response'][:100] + "..." if len(result['response']) > 100 else result['response']
            print(f"   {response_preview}")
            
            print(f"ğŸ–¼ï¸  ç”»åƒ: {'âœ…' if result['image_base64'] else 'âŒ'}")
            print(f"ğŸ·ï¸  ãƒˆãƒ”ãƒƒã‚¯: {', '.join(result['related_topics']) if result['related_topics'] else 'ãªã—'}")
            print(f"ğŸ“Š ä¿¡é ¼åº¦: {result['confidence']}")
            
            if i <= 8:
                is_valid = (
                    result['confidence'] in ['é«˜', 'ä¸­'] and
                    len(result['response'].strip()) > 50 and
                    "ãã®æƒ…å ±ã¯æŒã£ã¦ã„ã¾ã›ã‚“" not in result['response']
                )
                if is_valid:
                    passed_tests += 1
                    print("âœ… ãƒ†ã‚¹ãƒˆæˆåŠŸ")
                else:
                    print("âš ï¸  ãƒ†ã‚¹ãƒˆå¤±æ•—")
            else:
                is_valid = (
                    result['confidence'] == 'ä½' and 
                    "ãã®æƒ…å ±ã¯æŒã£ã¦ã„ã¾ã›ã‚“" in result['response']
                )
                if is_valid:
                    passed_tests += 1
                    print("âœ… ãƒ†ã‚¹ãƒˆæˆåŠŸï¼ˆæ­£ã—ãæ‹’å¦ï¼‰")
                else:
                    print("âš ï¸  ãƒ†ã‚¹ãƒˆå¤±æ•—ï¼ˆæ‹’å¦ã™ã¹ãï¼‰")
                
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        
        print("-" * 50)
    
    print(f"\nğŸ“‹ ãƒ†ã‚¹ãƒˆæ¦‚è¦:")
    print(f"   æˆåŠŸã—ãŸãƒ†ã‚¹ãƒˆ: {passed_tests}/{total_tests}")
    print(f"   æˆåŠŸç‡: {(passed_tests/total_tests)*100:.1f}%")
    
    if passed_tests == total_tests:
        print("ğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
    elif passed_tests >= total_tests * 0.8:
        print("âœ… ã»ã¨ã‚“ã©ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸã€‚")
    else:
        print("âš ï¸  ã„ãã¤ã‹ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    try:
        print("\nğŸ¤– ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚’åˆæœŸåŒ–ä¸­...")
        create_sample_images()
        kb = EnhancedBusinessKnowledgeBase(business_data, embedding_model)
        chatbot = EnhancedBusinessChatbot(model, tokenizer, kb)
        print("âœ… ãƒãƒ£ãƒƒãƒˆã®æº–å‚™ãŒã§ãã¾ã—ãŸï¼")
        
        # ã‚³ãƒ¡ãƒ³ãƒˆã‚’å¤–ã—ã¦ä½¿ç”¨ã—ã¦ãã ã•ã„:
        interactive_mode()
        # run_tests()
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ã•ã‚ˆã†ãªã‚‰ï¼")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")