import torch
from transformers import T5ForConditionalGeneration, T5Tokenizer
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
import base64
from PIL import Image, ImageDraw, ImageFont
import io
import os
import time
from typing import List, Dict, Tuple, Optional

print("ğŸ”„ æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™... (åˆå›å®Ÿè¡Œæ™‚ã¯æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)")

model_name = "sonoisa/t5-base-japanese"
tokenizer = T5Tokenizer.from_pretrained(model_name)
model = T5ForConditionalGeneration.from_pretrained(model_name)
model.eval()
embedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-mpnet-base-v2')
kb = None
chatbot = None

print("âœ… ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸ!")

def initialize_bot():
    global kb, chatbot
    kb = EnhancedBusinessKnowledgeBase(business_data, embedding_model)
    chatbot = EnhancedBusinessChatbot(model, tokenizer, kb)

def enhanced_chat_response(message: str) -> dict:
    if chatbot is None:
        return {
            "response": "ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚",
            "image_base64": None,
            "confidence": "ä½",
            "related_topics": []
        }
    
    try:
        result = chatbot.get_response(message)
        return {
            "response": result['response'],
            "image_base64": result.get('image_base64'),
            "confidence": result.get('confidence', 'ä½'),
            "related_topics": result.get('related_topics', [])
        }
    except Exception as e:
        print(f"Error in enhanced_chat_response: {str(e)}")
        return {
            "response": "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚",
            "image_base64": None,
            "confidence": "ä½",
            "related_topics": []
        }

business_data = [
    {
        "question": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã¯ä½•ã‚’ã™ã‚‹ä¼šç¤¾ã§ã™ã‹ï¼Ÿ",
        "answer": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã¯ã€æ±äº¬ã‚’æ‹ ç‚¹ã¨ã™ã‚‹B2Bãƒ•ã‚£ãƒ³ãƒ†ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã§ã€æ©Ÿé–¢æŠ•è³‡å®¶ã‚„ã‚¢ã‚»ãƒƒãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ãƒ‡ãƒ¼ã‚¿é‹ç”¨ã‚’é©æ–°ã™ã‚‹åŒ…æ‹¬çš„ãªSaaSãƒ‡ãƒ¼ã‚¿ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚å½“ç¤¾ã®AIæ­è¼‰ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã¯ã€è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚’è‡ªå‹•åŒ–ã—ã€è‡ªå‹•ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™ã€‚éæ§‹é€ åŒ–é‡‘èãƒ‡ãƒ¼ã‚¿ã‚’å®Ÿç”¨çš„ãªæ´å¯Ÿã«å¤‰æ›ã—ã€æŠ•è³‡ãƒãƒ¼ãƒ ã®æ‰‹ä½œæ¥­ã«ã‚ˆã‚‹Excelä½œæ¥­ã‚’æœ€å¤§80%å‰Šæ¸›ã™ã‚‹ã“ã¨ã‚’å°‚é–€ã¨ã—ã¦ã„ã¾ã™ã€‚å½“ç¤¾ã®ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã¯æ—¢å­˜ã®ã‚·ã‚¹ãƒ†ãƒ ã¨ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«çµ±åˆã•ã‚Œã€å¤§è¦æ¨¡ãªæ©Ÿé–¢æŠ•è³‡å®¶ã®ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã‚’ç®¡ç†ã™ã‚‹ãŸã‚ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã‚’æä¾›ã—ã¾ã™ã€‚",
        "category": "company_overview",
        "image_path": "images/company_overview.png",
        "related_topics": ["ã‚µãƒ¼ãƒ“ã‚¹", "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼", "è‡ªå‹•åŒ–"]
    },
    {
        "question": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã¯ã„ã¤è¨­ç«‹ã•ã‚Œã¾ã—ãŸã‹ï¼Ÿ",
        "answer": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã¯ã€é‡‘èã‚»ã‚¯ã‚¿ãƒ¼ã®ãƒ‡ã‚¸ã‚¿ãƒ«ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãŒè‘—ã—ã„æ™‚æœŸã®2019å¹´12æœˆã«æ±äº¬ã§è¨­ç«‹ã•ã‚Œã¾ã—ãŸã€‚è¨­ç«‹ä»¥æ¥ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ™ãƒ¼ã‚¹ã¨ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼æ©Ÿèƒ½ã®ä¸¡é¢ã§æ€¥é€Ÿãªæˆé•·ã‚’é‚ã’ã¦ã„ã¾ã™ã€‚å½“ç¤¾ã¯ã€æ©Ÿé–¢æŠ•è³‡é‹ç”¨ã«ãŠã„ã¦ã‚ˆã‚ŠåŠ¹ç‡çš„ã§é€æ˜æ€§ãŒé«˜ãã€è‡ªå‹•åŒ–ã•ã‚ŒãŸã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å‰µé€ ã™ã‚‹ã¨ã„ã†ãƒ“ã‚¸ãƒ§ãƒ³ã‹ã‚‰ç”Ÿã¾ã‚Œã¾ã—ãŸã€‚å‰µæ¥­è€…ãŸã¡ã¯ã€æŠ•è³‡é‹ç”¨ã¨ãƒ‡ãƒ¼ã‚¿ã‚·ã‚¹ãƒ†ãƒ ã«ãŠã‘ã‚‹è±Šå¯ŒãªçµŒé¨“ã‚’æ´»ã‹ã—ã€æ—¥æœ¬å¸‚å ´ã«ãŠã‘ã‚‹é«˜åº¦ãªãƒ•ã‚£ãƒ³ãƒ†ãƒƒã‚¯ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã®éœ€è¦ã®é«˜ã¾ã‚Šã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚",
        "category": "company_history",
        "image_path": "images/company_timeline.png",
        "related_topics": ["è¨­ç«‹", "æˆé•·", "æ±äº¬"]
    },
    {
        "question": "ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã®ãƒãƒ¼ãƒ ã®è¦æ¨¡ã¯ã©ã®ãã‚‰ã„ã§ã™ã‹ï¼Ÿ",
        "answer": "2025å¹´ç¾åœ¨ã€ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¢ãƒ«ãƒ•ã‚¡ã¯å–ç· å½¹ã€æŠ€è¡“é¡§å•ã€ã‚³ã‚¢ã‚¹ã‚¿ãƒƒãƒ•ã‚’å«ã‚ã€15-20åç¨‹åº¦ã®é«˜åº¦ãªã‚¹ã‚­ãƒ«ã‚’æŒã¤ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã‚’é›‡ç”¨ã—ã¦ã„ã¾ã™ã€‚å½“ç¤¾ã®ãƒãƒ¼ãƒ ã¯ã€ãƒ•ã‚£ãƒ³ãƒ†ãƒƒã‚¯ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã€ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã€é‡‘èã‚µãƒ¼ãƒ“ã‚¹ã«ã‚ãŸã‚‹å°‚é–€çŸ¥è­˜ã‚’æŒã¤ã€å¤šæ§˜ã§å›½éš›çš„ãªè¦–é‡ã‚’æŒã¤å¾“æ¥­å“¡ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚ä¸–ç•Œæœ‰æ•°ã®é‡‘èæ©Ÿé–¢ã€ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ä¼æ¥­ã€ã‚³ãƒ³ã‚µãƒ«ãƒ†ã‚£ãƒ³ã‚°ä¼šç¤¾ã§ã®çµŒé¨“ã‚’æŒã¤ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼ã¨å…±ã«ã€åŠ¹ç‡çš„ãªçµ„ç¹”æ§‹é€ ã‚’ç¶­æŒã—ã¦ã„ã¾ã™ã€‚å½“ç¤¾ã®æ–‡åŒ–ã¯ã€ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã€ç¶™ç¶šçš„ãªå­¦ç¿’ã€æ©Ÿé–¢æŠ•è³‡å®¶ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¸ã®å“è¶Šã—ãŸä¾¡å€¤æä¾›ã‚’é‡è¦–ã—ã¦ã„ã¾ã™ã€‚",
        "category": "team_info",
        "image_path": "images/team_structure.png",
        "related_topics": ["ã‚¹ã‚¿ãƒƒãƒ•", "å°‚é–€çŸ¥è­˜", "ä¼æ¥­æ–‡åŒ–"]
    }
]

class EnhancedBusinessKnowledgeBase:
    def __init__(self, data: List[Dict], embedding_model):
        self.data = data
        self.embedding_model = embedding_model
        self.index = None
        self._build_index()

    def _build_index(self):
        questions = [item["question"] for item in self.data]
        embeddings = self.embedding_model.encode(questions)
        dimension = embeddings.shape[1]
        
        self.index = faiss.IndexFlatL2(dimension)
        self.index.add(np.array(embeddings).astype('float32'))

    def get_most_similar(self, query: str, k: int = 3) -> List[Tuple[int, float]]:
        query_embedding = self.embedding_model.encode([query])
        D, I = self.index.search(np.array(query_embedding).astype('float32'), k)
        return list(zip(I[0], D[0]))

    def get_response(self, query: str) -> Dict:
        try:
            similar_questions = self.get_most_similar(query, k=1)
            best_match_idx, distance = similar_questions[0]
            
            if best_match_idx >= len(self.data):
                return {
                    'answer': 'ã™ã¿ã¾ã›ã‚“ã€ãã®è³ªå•ã«å¯¾ã™ã‚‹å›ç­”ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚',
                    'confidence': 'ä½',
                    'distance': 999,
                    'related_topics': []
                }
            
            confidence = "é«˜" if distance < 1.5 else "ä¸­" if distance < 2.0 else "ä½"
            
            response_data = self.data[best_match_idx].copy()
            response_data['confidence'] = confidence
            response_data['distance'] = distance
            
            return response_data
        except Exception as e:
            print(f"Error in get_response: {str(e)}")
            return {
                'answer': 'ã™ã¿ã¾ã›ã‚“ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚',
                'confidence': 'ä½',
                'distance': 999,
                'related_topics': []
            }

class EnhancedBusinessChatbot:
    def __init__(self, model, tokenizer, knowledge_base):
        self.model = model
        self.tokenizer = tokenizer
        self.knowledge_base = knowledge_base

    def get_response(self, query: str) -> Dict:
        try:
            print(f"Processing query in chatbot: {query}")
            response_data = self.knowledge_base.get_response(query)
            print(f"Knowledge base response: {response_data}")
            
            image_base64 = None
            if response_data.get('image_path'):
                try:
                    image_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), response_data['image_path'])
                    if os.path.exists(image_path):
                        with Image.open(image_path) as img:
                            if img.mode == 'RGBA':
                                img = img.convert('RGB')
                            
                            img_byte_arr = io.BytesIO()
                            img.save(img_byte_arr, format='JPEG')
                            img_byte_arr = img_byte_arr.getvalue()
                            
                            image_base64 = base64.b64encode(img_byte_arr).decode('utf-8')
                except Exception as e:
                    print(f"ç”»åƒã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")

            return {
                'response': response_data.get('answer', 'ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ'),
                'image_base64': image_base64,
                'confidence': response_data.get('confidence', 'ä½'),
                'related_topics': response_data.get('related_topics', [])
            }
        except Exception as e:
            print(f"Error in chatbot response: {str(e)}")
            return {
                'response': 'ã™ã¿ã¾ã›ã‚“ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚',
                'image_base64': None,
                'confidence': 'ä½',
                'related_topics': []
            }